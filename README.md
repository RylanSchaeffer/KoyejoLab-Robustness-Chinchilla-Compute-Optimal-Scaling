# Chinchilla Compute-Optimal Scaling of Language Models Is Surprisingly Robust

![](notebooks/01_epoch_research_fitting/results/compute_optimal_tokens_per_parameter_by_models_parameters.png)

## Installation

1. (Optional) Update conda:

`conda update -n base -c defaults conda -y`

2. Create and activate the conda environment:

`conda create -n chinchilla_env python=3.11 -y && conda activate chinchilla_env`

3. Install the required packages:

`pip install autograd matplotlib pandas scipy seaborn`

## Credit

Our Chinchilla fitting code was adapted from Epoch AI's [Chinchilla Scaling: A Replication Attempt](https://github.com/epoch-research/analyzing-chinchilla/).

## Running


## Contributing

Contributions are welcome! Please format your code with [black](https://github.com/psf/black) before submitting PRs.

## Citing

To cite this work, please use:

```bibtex
```

## Contact

Questions? Comments? Interested in collaborating?
Open an issue or email rschaef@cs.stanford.edu or any of the other authors.